import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
from Bio import Entrez
from docx import Document
from PIL import Image
import io
import time
import os

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="AI é†«å­¸æœŸåˆŠå¯©ç¨¿åŠ©æ‰‹ (Word/PDF/åœ–æª”)", layout="wide")

# --- 2. å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®šé¢æ¿")
    gemini_api_key = st.text_input("è¼¸å…¥ Google Gemini API Key", type="password")
    
    email_address = st.text_input(
        "è¼¸å…¥ Email (PubMed è¦å®š)", 
        value="doctor@example.com",
        help="NCBI è¦æ±‚ä½¿ç”¨ PubMed API æ™‚éœ€é™„ä¸Šè¯çµ¡ Emailã€‚"
    )
    
    st.markdown("---")
    st.info("âœ… æ¨¡å‹ï¼šGemini 1.5 Flash (å¿«é€Ÿã€é•·æ–‡æœ¬)")
    st.markdown("### æ”¯æ´æ ¼å¼èªªæ˜")
    st.markdown("""
    - **PDF**: æ¨™æº–æ ¼å¼
    - **Word (.docx)**: å®Œç¾æ”¯æ´
    - **Word (.doc)**: èˆŠç‰ˆæ ¼å¼ (å»ºè­°å¦å­˜ç‚º .docx ä»¥ç¢ºä¿è®€å–æˆåŠŸ)
    - **åœ–ç‰‡**: JPG, PNG, TIFF (è‡ªå‹•è¦–è¦ºè¾¨è­˜)
    """)

Entrez.email = email_address

# --- 3. åˆå§‹åŒ– Gemini ---
def get_gemini_model(api_key):
    genai.configure(api_key=api_key)
    return genai.GenerativeModel('gemini-1.5-flash')

# --- 4. æª”æ¡ˆè®€å–å·¥å…· ---

def get_text_from_pdf(file_obj):
    try:
        reader = PdfReader(file_obj)
        text = ""
        for page in reader.pages:
            extract = page.extract_text()
            if extract: text += extract
        return text
    except Exception as e:
        return f"[PDF è®€å–éŒ¯èª¤: {e}]"

def get_text_from_word(file_obj, file_ext):
    """
    è™•ç† Word æª”æ¡ˆ (.docx å’Œ .doc)
    """
    try:
        # å˜—è©¦ä½¿ç”¨ python-docx è®€å–
        # python-docx åŸç”Ÿåªæ”¯æ´ .docx
        doc = Document(file_obj)
        text = "\n".join([para.text for para in doc.paragraphs])
        return text
    except Exception as e:
        # å¦‚æœè®€å–å¤±æ•—ï¼Œé€šå¸¸æ˜¯å› ç‚ºä½¿ç”¨è€…ä¸Šå‚³äº†èˆŠç‰ˆ .doc
        if "doc" in file_ext and "docx" not in file_ext:
            return "âš ï¸ [æ ¼å¼æç¤º]: åµæ¸¬åˆ°èˆŠç‰ˆ Word (.doc) æ ¼å¼ã€‚ç‚ºäº†ç¢ºä¿åˆ†æç²¾ç¢ºåº¦ï¼Œå»ºè­°æ‚¨å°‡æª”æ¡ˆæ‰“é–‹ä¸¦ã€Œå¦å­˜æ–°æª”ã€ç‚º .docx æ ¼å¼å¾Œå†ä¸Šå‚³ã€‚"
        else:
            return f"[Word è®€å–éŒ¯èª¤: {e}]"

def analyze_image_content(image_file, model):
    try:
        image = Image.open(image_file)
        # é‡å° TIFF åšç›¸å®¹æ€§è½‰æ› (Gemini æœ‰æ™‚å°åŸå§‹ TIFF æ”¯æ´åº¦ä¸ä¸€)
        if image.format == 'TIFF':
            buffered = io.BytesIO()
            image.save(buffered, format="PNG")
            image = Image.open(buffered)
            
        prompt = "é€™æ˜¯é†«å­¸è«–æ–‡çš„é™„åœ–ã€‚è«‹è©³ç´°æè¿°æ•¸æ“šã€è¶¨å‹¢èˆ‡é—œéµè³‡è¨Šã€‚"
        response = model.generate_content([prompt, image])
        return response.text
    except Exception as e:
        return f"[åœ–ç‰‡åˆ†æéŒ¯èª¤: {e}]"

# --- 5. PubMed æœå°‹ ---
def search_pubmed(keywords, max_results=5):
    try:
        search_term = f"{keywords} AND (2024/01/01[Date - Publication] : 3000[Date - Publication])"
        handle = Entrez.esearch(db="pubmed", term=search_term, retmax=max_results, sort="date")
        record = Entrez.read(handle)
        handle.close()
        
        id_list = record["IdList"]
        if not id_list:
            return "æœªæ‰¾åˆ° 2024 å¹´å¾Œçš„æœ€æ–°ç›¸é—œæ–‡ç»ã€‚"

        handle = Entrez.efetch(db="pubmed", id=id_list, rettype="abstract", retmode="text")
        abstracts = handle.read()
        handle.close()
        return abstracts
    except Exception as e:
        return f"PubMed API é€£ç·šéŒ¯èª¤: {e}"

# --- 6. AI åˆ†ææµç¨‹ ---
def run_full_analysis(combined_text, api_key):
    model = get_gemini_model(api_key)
    
    # A. é—œéµå­—
    st.status("æ­¥é©Ÿ 1/3: æå–é—œéµå­—...", expanded=True)
    keyword_prompt = f"è«‹å¾ä»¥ä¸‹å…§å®¹æå– 3-5 å€‹é†«å­¸é—œéµå­— (MeSH terms)ï¼Œç”¨è‹±æ–‡ç©ºæ ¼åˆ†éš”ï¼š\n{combined_text[:5000]}"
    try:
        kw_resp = model.generate_content(keyword_prompt)
        keywords = kw_resp.text.strip()
        st.success(f"é—œéµå­—: {keywords}")
    except:
        return "Error: API é€£ç·šå¤±æ•—"

    # B. PubMed
    st.status("æ­¥é©Ÿ 2/3: æœå°‹ PubMed...", expanded=True)
    pubmed_data = search_pubmed(keywords)
    
    # C. å¯©ç¨¿
    st.status("æ­¥é©Ÿ 3/3: ç”Ÿæˆå¯©ç¨¿å ±å‘Š...", expanded=True)
    review_prompt = f"""
    è§’è‰²ï¼šè³‡æ·±è‡¨åºŠé†«å¸«ã€‚
    ä»»å‹™ï¼šå¯©é–±åŒäº‹çš„æŠ•ç¨¿è«–æ–‡ï¼Œèªæ°£å£èªåŒ–ã€å°ˆæ¥­ä¸”ç›´æ¥ã€‚
    
    å…§å®¹åŒ…å«ï¼š
    1. **æ•´é«”è©•åƒ¹**ï¼šç°¡è¿°ç ”ç©¶ç›®çš„èˆ‡åƒ¹å€¼ã€‚
    2. **æ–‡ç»å°ç…§ (Reality Check)**ï¼šå°æ¯”ä¸‹æ–¹æä¾›çš„ 2024-2025 æœ€æ–°æ–‡ç»ï¼ŒæŒ‡å‡ºæœ¬ç ”ç©¶æ˜¯å¦éæ™‚æˆ–æœ‰è¡çªã€‚
    3. **å¾…é‡æ¸…å•é¡Œ (Queries)**ï¼š3-5 å€‹å°–éŠ³å•é¡Œ (å¦‚æ¨£æœ¬ã€çµ±è¨ˆã€æ’é™¤æ¨™æº–)ã€‚
    4. **æœ€çµ‚åˆ¤æ±º (Recommendation)**ï¼šè«‹å¾ [Accept, Minor Revision, Major Revision, Reject] æ“‡ä¸€ä¸¦ç²—é«”æ¨™ç¤ºï¼Œé™„ä¸Šç†ç”±ã€‚

    ---
    ã€æŠ•ç¨¿å…§å®¹ã€‘
    {combined_text[:20000]}

    ã€æœ€æ–°æ–‡ç»ã€‘
    {pubmed_data}
    ---
    è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚
    """
    return model.generate_content(review_prompt).text

# --- 7. ä¸»ä»‹é¢ ---
st.title("ğŸ©º AI é†«å­¸æœŸåˆŠå¯©ç¨¿åŠ©æ‰‹")
st.markdown("æ”¯æ´ **PDF, Word (.docx/.doc), åœ–æª”** å¤šæª”æ•´åˆåˆ†æã€‚")

# é€™è£¡åŠ å…¥ 'doc' åˆ°æ”¯æ´åˆ—è¡¨
uploaded_files = st.file_uploader(
    "è«‹é¸æ“‡æª”æ¡ˆ (å¯å¤šé¸)", 
    type=['pdf', 'docx', 'doc', 'jpg', 'png', 'tiff', 'tif'],
    accept_multiple_files=True
)

if uploaded_files and gemini_api_key:
    if st.button("é–‹å§‹æ•´åˆåˆ†æ", type="primary"):
        model = get_gemini_model(gemini_api_key)
        combined_text = ""
        progress = st.progress(0)
        
        for i, file in enumerate(uploaded_files):
            ext = file.name.split('.')[-1].lower()
            combined_text += f"\n\n--- File: {file.name} ---\n"
            
            try:
                if ext == 'pdf':
                    combined_text += get_text_from_pdf(file)
                elif ext in ['docx', 'doc']:
                    # å‘¼å«æ–°çš„ Word è™•ç†å‡½å¼
                    combined_text += get_text_from_word(file, ext)
                elif ext in ['jpg', 'jpeg', 'png', 'tiff', 'tif']:
                    combined_text += f"\n[åœ–è¡¨]: {analyze_image_content(file, model)}\n"
                    time.sleep(1)
            except Exception as e:
                combined_text += f"[è®€å–éŒ¯èª¤: {e}]"
            
            progress.progress((i + 1) / len(uploaded_files))
            
        result = run_full_analysis(combined_text, gemini_api_key)
        if result and "Error" not in result:
            st.divider()
            st.markdown("### ğŸ“ é†«å¸«å¯©ç¨¿å ±å‘Š")
            st.markdown(result)
            st.download_button("ä¸‹è¼‰å ±å‘Š", result, "review.txt")
        elif "Error" in result:
             st.error("åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹æª¢æŸ¥ API Key æˆ–ç¶²è·¯ã€‚")

elif not gemini_api_key:
    st.warning("è«‹å…ˆè¼¸å…¥ Google Gemini API Key")
