import streamlit as st
import openai
from pypdf import PdfReader
from Bio import Entrez
from docx import Document
from PIL import Image
import io
import base64

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="å…¨èƒ½é†«å­¸æœŸåˆŠå¯©ç¨¿åŠ©æ‰‹", layout="wide")

with st.sidebar:
    st.header("è¨­å®š")
    openai_api_key = st.text_input("è¼¸å…¥ OpenAI API Key", type="password")
    # é€™è£¡è§£é‡‹äº†ç‚ºä»€éº¼éœ€è¦ Email
    email_address = st.text_input(
        "è¼¸å…¥ Email (NCBI è¦æ±‚)", 
        value="doctor@example.com",
        help="NCBI è¦æ±‚ä½¿ç”¨ API æ™‚éœ€é™„ä¸Šè¯çµ¡ Emailï¼Œè‹¥ç™¼ç”Ÿé€£ç·šé »ç‡éé«˜æ™‚ä»–å€‘å¯èƒ½æœƒé€šçŸ¥æ‚¨ã€‚"
    )
    st.markdown("---")
    st.info("ğŸ’¡ æç¤ºï¼šæ‚¨å¯ä»¥ä¸€æ¬¡é¸å–å¤šå€‹æª”æ¡ˆ (PDF, Word, åœ–æª”) ä¸Šå‚³ï¼ŒAI æœƒè‡ªå‹•åˆä½µé–±è®€ã€‚")

Entrez.email = email_address

# --- å·¥å…·å‡½å¼ (è®€å–å„é¡æª”æ¡ˆ) ---

def get_text_from_pdf(file_obj):
    try:
        reader = PdfReader(file_obj)
        text = ""
        for page in reader.pages:
            extract = page.extract_text()
            if extract: text += extract
        return text
    except Exception as e:
        return f"[PDFè®€å–éŒ¯èª¤: {e}]"

def get_text_from_docx(file_obj):
    try:
        doc = Document(file_obj)
        text = "\n".join([para.text for para in doc.paragraphs])
        return text
    except Exception as e:
        return f"[Wordè®€å–éŒ¯èª¤: {e}]"

def get_text_from_image(file_obj, api_key):
    """åˆ©ç”¨ GPT-4o Vision è®€å–åœ–è¡¨å…§å®¹"""
    try:
        # è½‰ç‚º Image ç‰©ä»¶
        image = Image.open(file_obj)
        
        # çµ±ä¸€è½‰ç‚º PNG ç”¨æ–¼ API å‚³è¼¸
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        base64_image = base64.b64encode(buffered.getvalue()).decode('utf-8')

        client = openai.OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "é€™æ˜¯é†«å­¸è«–æ–‡çš„åœ–è¡¨æˆ–é™„åœ–ã€‚è«‹è©³ç´°æè¿°åœ–ç‰‡ä¸­çš„æ•¸æ“šã€æ¨™é¡Œèˆ‡æ–‡å­—å…§å®¹ã€‚"},
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64_image}"}}
                    ]
                }
            ],
            max_tokens=1000
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"[åœ–ç‰‡è¾¨è­˜éŒ¯èª¤: {e}]"

# --- æ ¸å¿ƒ AI åˆ†æå‡½å¼ ---

def search_pubmed(keywords, max_results=5):
    try:
        # æœå°‹ 2024 å¹´è‡³ä»Šçš„æ–‡ç« 
        search_term = f"{keywords} AND (2024/01/01[Date - Publication] : 3000[Date - Publication])"
        handle = Entrez.esearch(db="pubmed", term=search_term, retmax=max_results, sort="date")
        record = Entrez.read(handle)
        handle.close()
        
        id_list = record["IdList"]
        if not id_list:
            return "æœªæ‰¾åˆ°ç›¸é—œæœ€æ–°æ–‡ç» (2024-Now)ã€‚"

        handle = Entrez.efetch(db="pubmed", id=id_list, rettype="abstract", retmode="text")
        abstracts = handle.read()
        handle.close()
        return abstracts
    except Exception as e:
        return f"PubMed API éŒ¯èª¤: {e}"

def analyze_and_generate_review(full_text, api_key):
    client = openai.OpenAI(api_key=api_key)
    
    # 1. æŠ“é—œéµå­—
    st.status("æ­¥é©Ÿ 1/3: ç¶œåˆåˆ†ææ‰€æœ‰æª”æ¡ˆå…§å®¹ï¼Œæå–ä¸»é¡Œ...", expanded=True)
    prompt_extract = f"""
    ä»¥ä¸‹æ˜¯æŠ•ç¨¿è«–æ–‡çš„å®Œæ•´å…§å®¹ï¼ˆåŒ…å« Cover letter, æ­£æ–‡, åœ–è¡¨èªªæ˜ï¼‰ã€‚
    è«‹æå– 3-5 å€‹æ ¸å¿ƒé†«å­¸é—œéµå­— (MeSH terms) ç”¨æ–¼æœå°‹æœ€æ–°æ–‡ç»ã€‚
    
    å…§å®¹ç‰‡æ®µ: 
    {full_text[:3000]}
    """
    kw_resp = client.chat.completions.create(
        model="gpt-4o", messages=[{"role": "user", "content": prompt_extract}]
    )
    keywords = kw_resp.choices[0].message.content
    st.success(f"æœå°‹é—œéµå­—: {keywords}")
    
    # 2. æŸ¥ PubMed
    st.status(f"æ­¥é©Ÿ 2/3: æ­£åœ¨æœå°‹ PubMed é—œæ–¼ {keywords} çš„æœ€æ–°æ–‡ç« ...", expanded=True)
    pubmed_data = search_pubmed(keywords)
    
    # 3. ç”Ÿæˆè©•è«–
    st.status("æ­¥é©Ÿ 3/3: æ­£åœ¨æ’°å¯«å£èªåŒ–å¯©é–±å ±å‘Š...", expanded=True)
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä½è³‡æ·±ã€è‡¨åºŠç¶“é©—è±å¯Œçš„é†«å¸«ã€‚é€™æ˜¯ä¸€ä»½ä¾†è‡ªä½ åŒäº‹çš„è«–æ–‡æŠ•ç¨¿ï¼ˆå¯èƒ½åŒ…å«å¤šå€‹æª”æ¡ˆå…§å®¹ï¼‰ã€‚
    
    èªæ°£è¦æ±‚ï¼š
    1. **å£èªåŒ–**ï¼šåƒæ˜¯åœ¨æ™¨æœƒæˆ–ä¼‘æ¯å®¤è·Ÿå­¸å¼Ÿå¦¹è¨è«–æ¡ˆå­ï¼Œä¸è¦åƒæ©Ÿå™¨äººã€‚
    2. **å°ˆæ¥­ä¸”ç›´æ¥**ï¼šé‡å°ç ”ç©¶è¨­è¨ˆã€æ•¸æ“šèˆ‡æœ€æ–°æ–‡ç»çš„å·®ç•°é€²è¡Œè©•è«–ã€‚
    
    ä½ çš„ä»»å‹™ï¼š
    1. **æ•´é«”è©•åƒ¹**ï¼šç¶œåˆ Cover letter èˆ‡æ­£æ–‡ï¼Œç°¡å–®èªªé€™ç¯‡æƒ³å¹¹å˜›ï¼Œæœ‰æ²’æœ‰æé ­ã€‚
    2. **æ–‡ç»å°ç…§**ï¼šåƒè€ƒæˆ‘çµ¦ä½ çš„ PubMed æœ€æ–°æ‘˜è¦ï¼ŒæŒ‡å‡ºé€™ç¯‡è«–æ–‡çš„è«–é»æ˜¯å¦è·Ÿç¾åœ¨æœ€æ–°çš„é¢¨å‘ä¸€è‡´ï¼Œé‚„æ˜¯æœ‰è¡çªï¼Ÿ
    3. **å¾…é‡æ¸…å•é¡Œ (Queries)**ï¼šåˆ—å‡º 3-5 å€‹ä½ éœ€è¦ä½œè€…è§£é‡‹æ¸…æ¥šçš„å•é¡Œï¼ˆä¾‹å¦‚æ•¸æ“šæ€ªæ€ªçš„ã€é¸æ¨£æœ‰åèª¤ç­‰ï¼‰ã€‚
    """

    user_prompt = f"""
    ã€æŠ•ç¨¿è«–æ–‡å®Œæ•´è³‡æ–™ã€‘:
    {full_text[:8000]} 
    (è‹¥å…§å®¹éé•·å·²æˆªæ–·ï¼Œè«‹æ ¹æ“šç¾æœ‰è³‡è¨Šåˆ†æ)

    ã€PubMed æœ€æ–°æ–‡ç» (2024-Now)ã€‘:
    {pubmed_data}
    
    è«‹ç”¨ç¹é«”ä¸­æ–‡è¼¸å‡ºã€‚
    """

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.7
    )
    return response.choices[0].message.content

# --- ä¸»ç¨‹å¼ ---
st.title("ğŸ©º å…¨èƒ½é†«å­¸æœŸåˆŠå¯©ç¨¿åŠ©æ‰‹ (å¤šæª”æ•´åˆç‰ˆ)")
st.markdown("æ”¯æ´ **ä¸€æ¬¡ä¸Šå‚³å¤šå€‹æª”æ¡ˆ** (Main text, Cover letter, Figures...)ï¼ŒAI æœƒè‡ªå‹•æ•´åˆåˆ†æã€‚")

# é€™è£¡é–‹å•Ÿ accept_multiple_files=True
uploaded_files = st.file_uploader(
    "è«‹é¸æ“‡æ‰€æœ‰ç›¸é—œæª”æ¡ˆ (å¯å¤šé¸)", 
    type=['pdf', 'docx', 'jpg', 'jpeg', 'png', 'tiff', 'tif'],
    accept_multiple_files=True
)

if uploaded_files and openai_api_key:
    if st.button("é–‹å§‹æ•´åˆåˆ†æ"):
        combined_text = ""
        
        # å»ºç«‹é€²åº¦æ¢
        progress_bar = st.progress(0)
        total_files = len(uploaded_files)
        
        for idx, file in enumerate(uploaded_files):
            file_name = file.name
            file_type = file_name.split('.')[-1].lower()
            
            # åœ¨æ–‡å­—ä¸­æ¨™è¨»é€™æ˜¯å“ªå€‹æª”æ¡ˆçš„å…§å®¹ï¼Œå¹«åŠ© AI å€åˆ†
            combined_text += f"\n\n--- æª”æ¡ˆä¾†æºï¼š{file_name} ---\n"
            
            extracted_text = ""
            try:
                if file_type == 'pdf':
                    extracted_text = get_text_from_pdf(file)
                elif file_type in ['docx', 'doc']:
                    extracted_text = get_text_from_docx(file)
                elif file_type in ['jpg', 'jpeg', 'png', 'tiff', 'tif']:
                    # ç‚ºäº†ç¯€çœ API å‘¼å«èˆ‡æ™‚é–“ï¼Œé€™è£¡å¯ä»¥é¸æ“‡æ˜¯å¦å°æ¯å¼µåœ–éƒ½è·‘ Vision
                    # æˆ–æ˜¯åªå°æœ‰ 'Table', 'Figure' å­—çœ¼çš„æª”æ¡ˆè·‘
                    extracted_text = f"[åœ–ç‰‡å…§å®¹]: {get_text_from_image(file, openai_api_key)}"
                
                combined_text += extracted_text
                
            except Exception as e:
                st.error(f"è™•ç†æª”æ¡ˆ {file_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
            # æ›´æ–°é€²åº¦æ¢
            progress_bar.progress((idx + 1) / total_files)

        st.success(f"å·²æˆåŠŸè®€å– {total_files} å€‹æª”æ¡ˆï¼Œé–‹å§‹ AI åˆ†æ...")
        
        # å‘¼å«åˆ†æå‡½å¼
        try:
            final_review = analyze_and_generate_review(combined_text, openai_api_key)
            st.divider()
            st.markdown("### ğŸ“ ç¶œåˆå¯©ç¨¿å»ºè­°")
            st.markdown(final_review)
        except Exception as e:
            st.error(f"AI åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")

elif not openai_api_key:
    st.warning("è«‹å…ˆè¼¸å…¥ OpenAI API Keyã€‚")
