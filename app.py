import streamlit as st
import openai
from pypdf import PdfReader
from Bio import Entrez
from docx import Document
from PIL import Image
import io
import base64

# --- è¨­å®šé é¢ ---
st.set_page_config(page_title="å…¨èƒ½é†«å­¸æœŸåˆŠå¯©ç¨¿åŠ©æ‰‹", layout="wide")

with st.sidebar:
    st.header("è¨­å®š")
    openai_api_key = st.text_input("è¼¸å…¥ OpenAI API Key", type="password")
    email_address = st.text_input("è¼¸å…¥æ‚¨çš„ Email (PubMed ç”¨)", value="doctor@example.com")
    st.markdown("---")
    st.info("æ”¯æ´æ ¼å¼ï¼šPDF, Word, JPG, PNG, TIFF")

Entrez.email = email_address

# --- å·¥å…·å‡½å¼å€ ---

def get_text_from_pdf(pdf_file):
    """è®€å– PDF æ–‡å­—"""
    try:
        reader = PdfReader(pdf_file)
        text = ""
        for page in reader.pages:
            extract = page.extract_text()
            if extract: text += extract
        return text
    except Exception as e:
        return f"PDF è®€å–éŒ¯èª¤: {e}"

def get_text_from_docx(docx_file):
    """è®€å– Word æ–‡å­—"""
    try:
        doc = Document(docx_file)
        text = "\n".join([para.text for para in doc.paragraphs])
        return text
    except Exception as e:
        return f"Word è®€å–éŒ¯èª¤: {e}"

def get_text_from_image(image_file, api_key, file_type):
    """
    åˆ©ç”¨ GPT-4o Vision è®€å–åœ–ç‰‡ä¸­çš„æ–‡å­—ã€‚
    åŒ…å«è‡ªå‹•å°‡ TIFF è½‰ç‚º PNG çš„é‚è¼¯ã€‚
    """
    client = openai.OpenAI(api_key=api_key)
    
    # è™•ç†åœ–ç‰‡æ ¼å¼
    image = Image.open(image_file)
    
    # å¦‚æœæ˜¯ TIFF æˆ–å…¶ä»–æ ¼å¼ï¼Œçµ±ä¸€è½‰ç‚º PNG ä»¥ç¢ºä¿ API ç›¸å®¹æ€§
    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    base64_image = base64.b64encode(buffered.getvalue()).decode('utf-8')

    st.caption("æ­£åœ¨ä½¿ç”¨ AI è¦–è¦ºè¾¨è­˜åœ–ç‰‡å…§å®¹...")
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "è«‹å°‡é€™å¼µåœ–ç‰‡ä¸­çš„é†«å­¸è«–æ–‡å…§å®¹è½‰éŒ„ç‚ºç´”æ–‡å­—ï¼Œå¿½ç•¥é ç¢¼æˆ–æµ®æ°´å°ï¼Œåªä¿ç•™å…§æ–‡ã€‚"},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{base64_image}"
                        }
                    }
                ]
            }
        ],
        max_tokens=2000
    )
    return response.choices[0].message.content

def search_pubmed(keywords, max_results=5):
    """æœå°‹ PubMed (ç¶­æŒä¸è®Š)"""
    try:
        # æœå°‹æœ€è¿‘ 2 å¹´
        search_term = f"{keywords} AND (2024[Date - Publication] : 3000[Date - Publication])"
        handle = Entrez.esearch(db="pubmed", term=search_term, retmax=max_results, sort="date")
        record = Entrez.read(handle)
        handle.close()
        
        id_list = record["IdList"]
        if not id_list:
            return "æœªæ‰¾åˆ°ç›¸é—œæœ€æ–°æ–‡ç»ã€‚"

        handle = Entrez.efetch(db="pubmed", id=id_list, rettype="abstract", retmode="text")
        abstracts = handle.read()
        handle.close()
        return abstracts
    except Exception as e:
        return f"PubMed æœå°‹éŒ¯èª¤: {e}"

def analyze_and_generate_review(paper_text, api_key):
    """
    æ•´åˆæµç¨‹ï¼š
    1. æŠ“é—œéµå­— -> 2. æŸ¥ PubMed -> 3. ç”Ÿæˆå£èªåŒ–è©•è«–
    """
    client = openai.OpenAI(api_key=api_key)
    
    # 1. æŠ“é—œéµå­—
    st.status("æ­¥é©Ÿ 1/3: åˆ†æè«–æ–‡ä¸»é¡Œèˆ‡é—œéµå­—...", expanded=True)
    prompt_extract = f"""
    è«‹é–±è®€ä»¥ä¸‹è«–æ–‡æ‘˜è¦æˆ–ç‰‡æ®µï¼Œæå– 3-5 å€‹ç”¨æ–¼ PubMed æœå°‹çš„æ ¸å¿ƒè‹±æ–‡é†«å­¸é—œéµå­— (MeSH terms ä½³)ã€‚
    åªå›å‚³é—œéµå­—ï¼Œç”¨ç©ºæ ¼éš”é–‹ã€‚
    
    å…§å®¹: {paper_text[:2000]}
    """
    kw_resp = client.chat.completions.create(
        model="gpt-4o", messages=[{"role": "user", "content": prompt_extract}]
    )
    keywords = kw_resp.choices[0].message.content
    st.success(f"é—œéµå­—: {keywords}")
    
    # 2. æŸ¥ PubMed
    st.status("æ­¥é©Ÿ 2/3: æœå°‹ PubMed æœ€æ–°æ–‡ç»...", expanded=True)
    pubmed_data = search_pubmed(keywords)
    with st.expander("é»æ“ŠæŸ¥çœ‹æŠ“å–åˆ°çš„æ–‡ç»æ‘˜è¦"):
        st.text(pubmed_data[:2000] + "...") # é è¦½éƒ¨åˆ†

    # 3. ç”Ÿæˆè©•è«–
    st.status("æ­¥é©Ÿ 3/3: ç”Ÿæˆå£èªåŒ–å¯©é–±å ±å‘Š...", expanded=True)
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä½è³‡æ·±ã€è‡¨åºŠç¶“é©—è±å¯Œçš„é†«å¸«å‰è¼©ã€‚ä½ æ­£åœ¨å”åŠ©åŒäº‹å¯©é–±è«–æ–‡ã€‚
    
    èªæ°£æŒ‡å¼•ï¼š
    - **é«˜åº¦å£èªåŒ–**ï¼šåƒæ˜¯åœ¨é†«ç”Ÿä¼‘æ¯å®¤å–å’–å•¡æ™‚çš„å°è©±ã€‚
    - **é¿å… AI è…”**ï¼šç¦æ­¢ä½¿ç”¨ã€Œé¦–å…ˆã€å…¶æ¬¡ã€ç¶œä¸Šæ‰€è¿°ã€é€™é¡å…«è‚¡æ–‡ã€‚
    - **å°ˆæ¥­ä½†è¼•é¬†**ï¼šä¾‹å¦‚ã€Œé€™ç¯‡è¬› HIFU çš„åˆ‡å…¥é»è »ç‰¹åˆ¥çš„ï¼Œä½†æˆ‘çœ‹äº†ä¸€ä¸‹æœ€æ–°çš„ paperï¼Œåƒ Chen et al. é‚£ç¯‡ï¼Œçµè«–å¥½åƒæœ‰é»å‡ºå…¥...ã€ã€‚
    
    ä»»å‹™ï¼š
    1. ç¸½çµé€™ç¯‡æ–‡ç« æƒ³è§£æ±ºä»€éº¼è‡¨åºŠå•é¡Œã€‚
    2. å°æ¯”æˆ‘æä¾›çš„ PubMed æœ€æ–°æ–‡ç»ï¼ŒæŒ‡å‡ºé€™ç¯‡æ–‡ç« çš„å‰µæ–°æˆ–éæ™‚ä¹‹è™•ã€‚
    3. åˆ—å‡º 3-5 å€‹å…·é«”ä¸”å°–éŠ³çš„å•é¡Œ (Questions for authors)ï¼Œé€™æ˜¯è¦ç”¨ä¾†å¹«ä½œè€…é‡æ¸…ç›²é»çš„ã€‚
    """

    user_prompt = f"""
    ã€æŠ•ç¨¿æ–‡ç« ç‰‡æ®µã€‘:
    {paper_text[:6000]}

    ã€PubMed æœ€æ–°ç›¸é—œæ–‡ç»ã€‘:
    {pubmed_data}
    
    è«‹ç”¨ç¹é«”ä¸­æ–‡è¼¸å‡ºå»ºè­°ã€‚
    """

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.7
    )
    return response.choices[0].message.content

# --- ä¸»ç¨‹å¼é‚è¼¯ ---
st.title("ğŸ©º å…¨èƒ½é†«å­¸æœŸåˆŠå¯©ç¨¿åŠ©æ‰‹")
st.markdown("æ”¯æ´ **PDF, Word, JPG, PNG, TIFF**ã€‚ä¸Šå‚³å¾Œè‡ªå‹•è¯ç¶²åˆ†æã€‚")

# å…è¨±ä¸Šå‚³å¤šç¨®æ ¼å¼
uploaded_file = st.file_uploader(
    "è«‹ä¸Šå‚³æª”æ¡ˆ", 
    type=['pdf', 'docx', 'jpg', 'jpeg', 'png', 'tiff', 'tif']
)

if uploaded_file and openai_api_key:
    if st.button("é–‹å§‹åˆ†æ"):
        raw_text = ""
        file_type = uploaded_file.name.split('.')[-1].lower()
        
        try:
            with st.spinner('æ­£åœ¨è®€å–æª”æ¡ˆå…§å®¹...'):
                # æ ¹æ“šå‰¯æª”ååˆ†æµè™•ç†
                if file_type == 'pdf':
                    raw_text = get_text_from_pdf(uploaded_file)
                
                elif file_type in ['docx', 'doc']:
                    raw_text = get_text_from_docx(uploaded_file)
                
                elif file_type in ['jpg', 'jpeg', 'png', 'tiff', 'tif']:
                    # åœ–ç‰‡éœ€è¦å‘¼å« API é€²è¡Œè¦–è¦ºè¾¨è­˜
                    raw_text = get_text_from_image(uploaded_file, openai_api_key, file_type)
                
                if len(raw_text) < 50:
                    st.error("è®€å–åˆ°çš„æ–‡å­—å¤ªå°‘ï¼Œè«‹ç¢ºèªæª”æ¡ˆå…§å®¹æ˜¯å¦æ¸…æ™°ã€‚")
                else:
                    # é€²å…¥åˆ†ææµç¨‹
                    final_review = analyze_and_generate_review(raw_text, openai_api_key)
                    st.divider()
                    st.markdown("### ğŸ“ é†«å¸«å¯©ç¨¿å»ºè­°")
                    st.markdown(final_review)

        except Exception as e:
            st.error(f"ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}")

elif not openai_api_key:
    st.warning("è«‹å…ˆè¼¸å…¥ OpenAI API Key æ‰èƒ½é‹ä½œã€‚")
